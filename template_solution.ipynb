{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoahBjongHoKim/IML_Projects_BoK/blob/Sara/template_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16163d2dd773fbc",
      "metadata": {
        "collapsed": false,
        "id": "f16163d2dd773fbc"
      },
      "source": [
        "# Task 3\n",
        "This serves as a template which will guide you through the implementation of this task. It is advised to first read the whole template and get a sense of the overall structure of the code before trying to fill in any of the TODO gaps.\n",
        "This is the jupyter notebook version of the template. For the python file version, please refer to the file `template_solution.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bmILUEF_8qgd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmILUEF_8qgd",
        "outputId": "476c4643-f088-4222-e644-0b18b4459d98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c95f1a3a9db8e3f9",
      "metadata": {
        "collapsed": false,
        "id": "c95f1a3a9db8e3f9"
      },
      "source": [
        "First, we import necessary libraries:\n",
        "\n",
        "just added whatever was needed, probably also stuff not needed anymore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "824a840beb8b323e",
      "metadata": {
        "id": "824a840beb8b323e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.io import read_image\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import torch.optim as optim\n",
        "# Add any other imports you need here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "82adb41ca8c23be6",
      "metadata": {
        "id": "82adb41ca8c23be6"
      },
      "outputs": [],
      "source": [
        "# The device is automatically set to GPU if available, otherwise CPU\n",
        "# If you want to force the device to CPU, you can change the line to\n",
        "# device = torch.device(\"cpu\")\n",
        "# When using the GPU, it is important that your model and all data are on the\n",
        "# same device.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W_xA-Ns1NagQ",
      "metadata": {
        "id": "W_xA-Ns1NagQ"
      },
      "source": [
        "This class to get an embedding from the pretrained network and not a prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7kZno_VQCnpQ",
      "metadata": {
        "id": "7kZno_VQCnpQ"
      },
      "outputs": [],
      "source": [
        "class NoFinalLayer(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(NoFinalLayer, self).__init__()\n",
        "        self.features = nn.Sequential(*list(original_model.children())[:-1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4qzzIBlXNsK_",
      "metadata": {
        "id": "4qzzIBlXNsK_"
      },
      "source": [
        "Reading all the stupid images and applying the pretrained network on them. Takes ages. Try to avoid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b3d5c760c9c963b",
      "metadata": {
        "id": "6b3d5c760c9c963b"
      },
      "outputs": [],
      "source": [
        "def generate_embeddings():\n",
        "    \"\"\"\n",
        "    Transform, resize and normalize the images and then use a pretrained model to extract\n",
        "    the embeddings.\n",
        "    \"\"\"\n",
        "    # TODO: define a transform to pre-process the images\n",
        "    # The required pre-processing depends on the pre-trained model you choose\n",
        "    # below.\n",
        "    # See https://pytorch.org/vision/stable/models.html#using-the-pre-trained-models\n",
        "\n",
        "    #Average image width: 453.9186\n",
        "    #Average image height: 306.4356\n",
        "    image_size = (306,454)\n",
        "    mean_per_channel = (161.6640330815327, 140.88972730355985, 111.99007629992748)\n",
        "    standard_deviation_per_channel_reciprocal = (1/57.38794298481981, 1/62.1605772577997, 1/70.41062360670296)\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize(mean = mean_per_channel, std= standard_deviation_per_channel_reciprocal),\n",
        "                             ])\n",
        "\n",
        "    path = \"/content/drive/MyDrive/task3_full\"\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/task3_full/dataset\", transform=train_transforms)\n",
        "    # Hint: adjust batch_size and num_workers to your PC configuration, so that you don't\n",
        "    # run out of memory (VRAM if on GPU, RAM if on CPU)\n",
        "\n",
        "    #we have to pass images of the same size to the DataLoader or it is unhappy (just like me)\n",
        "    train_loader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=64, #teiler von 10001 #maybe set to 32 if it does not work\n",
        "                              shuffle=False, #set this to true?\n",
        "                              pin_memory=True, num_workers=16, #and this to 8, google says 2 originally 16\n",
        "                              )\n",
        "\n",
        "    # TODO: define a model for extraction of the embeddings (Hint: load a pretrained model,\n",
        "    #  more info here: https://pytorch.org/vision/stable/models.html)\n",
        "    weights = ResNet50_Weights.DEFAULT\n",
        "    model_init = resnet50(weights=weights)\n",
        "    model = NoFinalLayer(model_init)\n",
        "    model.to(device)\n",
        "    embedding_size = 2048 #this works, I tried it\n",
        "\n",
        "    # TODO: pick your model\n",
        "    num_images = len(train_dataset)\n",
        "    print(num_images)\n",
        "    print(embedding_size)\n",
        "    embeddings_list = []\n",
        "    # TODO: Use the model to extract the embeddings. Hint: remove the last layers of the\n",
        "    # model to access the embeddings the model generates.\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    number=0\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for images, _ in train_loader:\n",
        "            #print(\"size :\", images.size(), \" type:\", images.type())\n",
        "            images = images.to(device)  # Move images to the device\n",
        "            # Forward pass through the model to get the output\n",
        "            number = number + 1\n",
        "            outputs = model(images) # Get both output and auxiliary output\n",
        "            # Extract embeddings from the output\n",
        "            embeddings_list.append(outputs.cpu().numpy().squeeze())   # Append embeddings to the list\n",
        "            print(\"Batch: \",number, \"/\",num_images/91)\n",
        "    embeddings_array = np.concatenate(embeddings_list, axis=0)\n",
        "    #embeddings_list = np.array(embeddings_list)\n",
        "    print(embeddings_array.shape)\n",
        "    assert(np.shape(embeddings_array) == (num_images, embedding_size))\n",
        "    np.save(\"/content/drive/MyDrive/task3_full/dataset/embeddings.npy\", embeddings_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IsThyr1P_w5D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsThyr1P_w5D",
        "outputId": "bddaec3c-3db5-47ff-e655-333504424fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 60.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10023\n",
            "2048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch:  1 / 110.14285714285714\n",
            "Batch:  2 / 110.14285714285714\n",
            "Batch:  3 / 110.14285714285714\n",
            "Batch:  4 / 110.14285714285714\n",
            "Batch:  5 / 110.14285714285714\n",
            "Batch:  6 / 110.14285714285714\n",
            "Batch:  7 / 110.14285714285714\n",
            "Batch:  8 / 110.14285714285714\n",
            "Batch:  9 / 110.14285714285714\n",
            "Batch:  10 / 110.14285714285714\n",
            "Batch:  11 / 110.14285714285714\n",
            "Batch:  12 / 110.14285714285714\n",
            "Batch:  13 / 110.14285714285714\n",
            "Batch:  14 / 110.14285714285714\n",
            "Batch:  15 / 110.14285714285714\n",
            "Batch:  16 / 110.14285714285714\n",
            "Batch:  17 / 110.14285714285714\n",
            "Batch:  18 / 110.14285714285714\n",
            "Batch:  19 / 110.14285714285714\n",
            "Batch:  20 / 110.14285714285714\n",
            "Batch:  21 / 110.14285714285714\n",
            "Batch:  22 / 110.14285714285714\n",
            "Batch:  23 / 110.14285714285714\n",
            "Batch:  24 / 110.14285714285714\n",
            "Batch:  25 / 110.14285714285714\n",
            "Batch:  26 / 110.14285714285714\n",
            "Batch:  27 / 110.14285714285714\n",
            "Batch:  28 / 110.14285714285714\n",
            "Batch:  29 / 110.14285714285714\n",
            "Batch:  30 / 110.14285714285714\n",
            "Batch:  31 / 110.14285714285714\n",
            "Batch:  32 / 110.14285714285714\n",
            "Batch:  33 / 110.14285714285714\n",
            "Batch:  34 / 110.14285714285714\n",
            "Batch:  35 / 110.14285714285714\n",
            "Batch:  36 / 110.14285714285714\n",
            "Batch:  37 / 110.14285714285714\n",
            "Batch:  38 / 110.14285714285714\n",
            "Batch:  39 / 110.14285714285714\n",
            "Batch:  40 / 110.14285714285714\n",
            "Batch:  41 / 110.14285714285714\n",
            "Batch:  42 / 110.14285714285714\n",
            "Batch:  43 / 110.14285714285714\n",
            "Batch:  44 / 110.14285714285714\n",
            "Batch:  45 / 110.14285714285714\n",
            "Batch:  46 / 110.14285714285714\n",
            "Batch:  47 / 110.14285714285714\n",
            "Batch:  48 / 110.14285714285714\n",
            "Batch:  49 / 110.14285714285714\n",
            "Batch:  50 / 110.14285714285714\n",
            "Batch:  51 / 110.14285714285714\n",
            "Batch:  52 / 110.14285714285714\n",
            "Batch:  53 / 110.14285714285714\n",
            "Batch:  54 / 110.14285714285714\n",
            "Batch:  55 / 110.14285714285714\n",
            "Batch:  56 / 110.14285714285714\n",
            "Batch:  57 / 110.14285714285714\n",
            "Batch:  58 / 110.14285714285714\n",
            "Batch:  59 / 110.14285714285714\n",
            "Batch:  60 / 110.14285714285714\n",
            "Batch:  61 / 110.14285714285714\n",
            "Batch:  62 / 110.14285714285714\n",
            "Batch:  63 / 110.14285714285714\n",
            "Batch:  64 / 110.14285714285714\n",
            "Batch:  65 / 110.14285714285714\n",
            "Batch:  66 / 110.14285714285714\n",
            "Batch:  67 / 110.14285714285714\n",
            "Batch:  68 / 110.14285714285714\n",
            "Batch:  69 / 110.14285714285714\n",
            "Batch:  70 / 110.14285714285714\n",
            "Batch:  71 / 110.14285714285714\n",
            "Batch:  72 / 110.14285714285714\n",
            "Batch:  73 / 110.14285714285714\n",
            "Batch:  74 / 110.14285714285714\n",
            "Batch:  75 / 110.14285714285714\n",
            "Batch:  76 / 110.14285714285714\n",
            "Batch:  77 / 110.14285714285714\n",
            "Batch:  78 / 110.14285714285714\n",
            "Batch:  79 / 110.14285714285714\n",
            "Batch:  80 / 110.14285714285714\n",
            "Batch:  81 / 110.14285714285714\n",
            "Batch:  82 / 110.14285714285714\n",
            "Batch:  83 / 110.14285714285714\n",
            "Batch:  84 / 110.14285714285714\n",
            "Batch:  85 / 110.14285714285714\n",
            "Batch:  86 / 110.14285714285714\n",
            "Batch:  87 / 110.14285714285714\n",
            "Batch:  88 / 110.14285714285714\n",
            "Batch:  89 / 110.14285714285714\n",
            "Batch:  90 / 110.14285714285714\n",
            "Batch:  91 / 110.14285714285714\n",
            "Batch:  92 / 110.14285714285714\n",
            "Batch:  93 / 110.14285714285714\n",
            "Batch:  94 / 110.14285714285714\n",
            "Batch:  95 / 110.14285714285714\n",
            "Batch:  96 / 110.14285714285714\n",
            "Batch:  97 / 110.14285714285714\n",
            "Batch:  98 / 110.14285714285714\n",
            "Batch:  99 / 110.14285714285714\n",
            "Batch:  100 / 110.14285714285714\n",
            "Batch:  101 / 110.14285714285714\n",
            "Batch:  102 / 110.14285714285714\n",
            "Batch:  103 / 110.14285714285714\n",
            "Batch:  104 / 110.14285714285714\n",
            "Batch:  105 / 110.14285714285714\n",
            "Batch:  106 / 110.14285714285714\n",
            "Batch:  107 / 110.14285714285714\n",
            "Batch:  108 / 110.14285714285714\n",
            "Batch:  109 / 110.14285714285714\n",
            "Batch:  110 / 110.14285714285714\n",
            "Batch:  111 / 110.14285714285714\n",
            "(10023, 2048)\n"
          ]
        }
      ],
      "source": [
        "print(device)\n",
        "generate_embeddings()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "335d91cc379d4f6b",
      "metadata": {
        "id": "335d91cc379d4f6b"
      },
      "outputs": [],
      "source": [
        "def get_data(file, train=True):\n",
        "    \"\"\"\n",
        "    Load the triplets from the file and generate the features and labels.\n",
        "\n",
        "    input: file: string, the path to the file containing the triplets\n",
        "          train: boolean, whether the data is for training or testing\n",
        "\n",
        "    output: X: numpy array, the features\n",
        "            y: numpy array, the labels\n",
        "    \"\"\"\n",
        "    triplets = []\n",
        "    with open(file) as f:\n",
        "        for line in f:\n",
        "            triplets.append(line)\n",
        "\n",
        "    # generate training data from triplets\n",
        "    train_dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/task3_full/dataset\",\n",
        "                                         transform=None)\n",
        "    filenames = [s[0].split('/')[-1].replace('.jpg', '') for s in train_dataset.samples]\n",
        "    embeddings = np.load('/content/drive/MyDrive/task3_full/dataset/embeddings.npy')\n",
        "    # TODO: Normalize the embeddings\n",
        "    #embeddings = torch.nn.functional.normalize(embeddings)\n",
        "\n",
        "    #Mean per channel: [161.6640330815327, 140.88972730355985, 111.99007629992748]\n",
        "    #Standard deviation per channel: [1/57.38794298481981, 1/62.1605772577997, 1/70.41062360670296]\n",
        "    #embeddings = torchvision.transforms.Normalize(embeddings, mean = [161.6640330815327, 140.88972730355985, 111.99007629992748],\n",
        "    #                                                         std = [57.38794298481981, 62.1605772577997, 70.41062360670296])\n",
        "    # Use numpy's L2 normalization\n",
        "    norm = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    # Normalize embeddings\n",
        "    embeddings_normalized = embeddings / norm\n",
        "    file_to_embedding = {}\n",
        "    for i in range(len(filenames)):\n",
        "        file_to_embedding[filenames[i]] = embeddings_normalized[i]\n",
        "    X = []\n",
        "    y = []\n",
        "    # use the individual embeddings to generate the features and labels for triplets\n",
        "    for t in triplets:\n",
        "        emb = [file_to_embedding[a] for a in t.split()]\n",
        "        X.append(np.hstack([emb[0], emb[1], emb[2]]))\n",
        "        y.append(1)\n",
        "        # Generating negative samples (data augmentation)\n",
        "        #if train:\n",
        "            #X.append(np.hstack([emb[0], emb[2], emb[1]]))\n",
        "            #y.append(0)\n",
        "    X = np.vstack(X)\n",
        "    y = np.hstack(y)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_triplet(file, train=True):\n",
        "    \"\"\"\n",
        "    Load the triplets from the file and generate the features and labels.\n",
        "\n",
        "    input: file: string, the path to the file containing the triplets\n",
        "          train: boolean, whether the data is for training or testing\n",
        "\n",
        "    output: X: numpy array, the features\n",
        "            y: numpy array, the labels\n",
        "    \"\"\"\n",
        "    triplets = []\n",
        "    with open(file) as f:\n",
        "        for line in f:\n",
        "            triplets.append(line)\n",
        "\n",
        "    # generate training data from triplets\n",
        "    train_dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/task3_full/dataset\",\n",
        "                                         transform=None)\n",
        "    filenames = [s[0].split('/')[-1].replace('.jpg', '') for s in train_dataset.samples]\n",
        "    embeddings = np.load('/content/drive/MyDrive/task3_full/dataset/embeddings.npy')\n",
        "    # TODO: Normalize the embeddings\n",
        "    #embeddings = torch.nn.functional.normalize(embeddings)\n",
        "\n",
        "    #Mean per channel: [161.6640330815327, 140.88972730355985, 111.99007629992748]\n",
        "    #Standard deviation per channel: [1/57.38794298481981, 1/62.1605772577997, 1/70.41062360670296]\n",
        "    #embeddings = torchvision.transforms.Normalize(embeddings, mean = [161.6640330815327, 140.88972730355985, 111.99007629992748],\n",
        "    #                                                         std = [57.38794298481981, 62.1605772577997, 70.41062360670296])\n",
        "    # Use numpy's L2 normalization\n",
        "    norm = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    # Normalize embeddings\n",
        "    embeddings_normalized = embeddings / norm\n",
        "    file_to_embedding = {}\n",
        "    for i in range(len(filenames)):\n",
        "        file_to_embedding[filenames[i]] = embeddings_normalized[i]\n",
        "    X = []\n",
        "    y = []\n",
        "    # use the individual embeddings to generate the features and labels for triplets\n",
        "    for t in triplets:\n",
        "        emb = [file_to_embedding[a] for a in t.split()]\n",
        "        X.append(np.hstack([emb[0], emb[1], emb[2]]))\n",
        "        y.append(1)\n",
        "        # Generating negative samples (data augmentation)\n",
        "        #if train:\n",
        "            #X.append(np.hstack([emb[0], emb[2], emb[1]]))\n",
        "            #y.append(0)\n",
        "    X = np.vstack(X)\n",
        "    y = np.hstack(y)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "8PG5b67roJTn"
      },
      "id": "8PG5b67roJTn",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2uv_S3nomRk4",
      "metadata": {
        "id": "2uv_S3nomRk4"
      },
      "source": [
        "We are given A, B, C\n",
        "A is the Anchor\n",
        "B is positive\n",
        "C is negative\n",
        "Then y = 1\n",
        "\n",
        "If we swap B, C (so A, C, B if original)\n",
        "A is the Anchor\n",
        "C is negative\n",
        "B is positive\n",
        "Then y = 0\n",
        "\n",
        "So given a triplet P1, P2, P3, label y+1 denotes the index of the negative (in embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abc48f07a1c0c478",
      "metadata": {
        "collapsed": false,
        "id": "abc48f07a1c0c478"
      },
      "source": [
        "Hint: adjust batch_size and num_workers to your PC configuration, so that you don't run out of memory (VRAM if on GPU, RAM if on CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6daf836a4adb0abe",
      "metadata": {
        "id": "6daf836a4adb0abe"
      },
      "outputs": [],
      "source": [
        "def create_loader_from_np(X, y = None, train = True, batch_size=64, shuffle=True, num_workers = 4):\n",
        "    \"\"\"\n",
        "    Create a torch.utils.data.DataLoader object from numpy arrays containing the data.\n",
        "\n",
        "    input: X: numpy array, the features\n",
        "           y: numpy array, the labels\n",
        "\n",
        "    output: loader: torch.data.util.DataLoader, the object containing the data\n",
        "    \"\"\"\n",
        "    if train:\n",
        "        # Attention: If you get type errors you can modify the type of the\n",
        "        # labels here\n",
        "        dataset = TensorDataset(torch.from_numpy(X).type(torch.float),\n",
        "                                torch.from_numpy(y).type(torch.long))\n",
        "    else:\n",
        "        dataset = TensorDataset(torch.from_numpy(X).type(torch.float))\n",
        "    loader = DataLoader(dataset=dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=shuffle,\n",
        "                        pin_memory=True, num_workers=num_workers)\n",
        "    return loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1baa5918f11a049",
      "metadata": {
        "collapsed": false,
        "id": "e1baa5918f11a049"
      },
      "source": [
        "TODO: define a model. Here, the basic structure is defined, but you need to fill in the details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fcd11318eb7b9488",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "fcd11318eb7b9488",
        "outputId": "086433e5-7686-4715-beec-8dfb42072204"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass TripletNet(nn.Module):\\n    def __init__(self):\\n        super(TripletNet, self).__init__()\\n        # Define your base network here\\n        self.base_network = nn.Sequential(\\n            nn.Linear(input_size, hidden_size),\\n            nn.ReLU(),\\n            nn.Linear(hidden_size, embedding_size),\\n        )\\n\\n    def forward(self, anchor, positive, negative):\\n        anchor_embedding = self.base_network(anchor)\\n        positive_embedding = self.base_network(positive)\\n        negative_embedding = self.base_network(negative)\\n        return anchor_embedding, positive_embedding, negative_embedding\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "    The model class, which defines our classifier.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        The constructor of the model.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(3*2048, 2048)\n",
        "        self.fc12 = nn.Linear(2048, 2048)\n",
        "        self.fc13 = nn.Linear(2048, 2048)\n",
        "        self.fc14 = nn.Linear(2048, 2048)\n",
        "        self.fc15 = nn.Linear(2048, 128)\n",
        "        self.fc3 = nn.Linear(128, 1)\n",
        "\n",
        "        # Print initial weights\n",
        "        print(\"Initial weights of the linear layer:\")\n",
        "        print(self.fc1.weight)\n",
        "        print(\"Initial bias of the linear layer:\")\n",
        "        print(self.fc1.bias)\n",
        "\n",
        "        # Initialize weights using Xavier initialization\n",
        "        init.xavier_uniform_(self.fc1.weight)\n",
        "        init.constant_(self.fc1.bias, 0)  # Initialize bias to zeros\n",
        "\n",
        "        # Print weights after initialization\n",
        "        print(\"Weights after Xavier initialization:\")\n",
        "        print(self.fc1.weight)\n",
        "        print(\"Bias after initialization:\")\n",
        "        print(self.fc1.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        The forward pass of the model.\n",
        "\n",
        "        input: x: torch.Tensor, the input to the model\n",
        "\n",
        "        output: x: torch.Tensor, the output of the model\n",
        "        \"\"\"\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc12(x))\n",
        "        x = F.relu(self.fc13(x))\n",
        "        x = F.relu(self.fc14(x))\n",
        "        x = F.relu(self.fc15(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\"\"\"\n",
        "class TripletNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TripletNet, self).__init__()\n",
        "        # Define your base network here\n",
        "        self.base_network = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, embedding_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        anchor_embedding = self.base_network(anchor)\n",
        "        positive_embedding = self.base_network(positive)\n",
        "        negative_embedding = self.base_network(negative)\n",
        "        return anchor_embedding, positive_embedding, negative_embedding\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rvvjs5jl26gS",
      "metadata": {
        "id": "rvvjs5jl26gS"
      },
      "outputs": [],
      "source": [
        "class TripletNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TripletNet, self).__init__()\n",
        "        # Define your base network here\n",
        "        self.base_network = nn.Sequential(\n",
        "            nn.Linear(2048, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        anchor_embedding = self.base_network(anchor)\n",
        "        positive_embedding = self.base_network(positive)\n",
        "        negative_embedding = self.base_network(negative)\n",
        "        return anchor_embedding, positive_embedding, negative_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6e1b0092e0b13f88",
      "metadata": {
        "id": "6e1b0092e0b13f88"
      },
      "outputs": [],
      "source": [
        "TRAIN_TRIPLETS = '/content/drive/MyDrive/task3_full/train_triplets.txt'\n",
        "\n",
        "# load the training data\n",
        "X, y = get_data(TRAIN_TRIPLETS)\n",
        "# Create data loaders for the training data\n",
        "#print(X)\n",
        "#print(y)\n",
        "train_loader = create_loader_from_np(X, y, train = True, batch_size=32)\n",
        "# delete the loaded training data to save memory, as the data loader copies\n",
        "del X\n",
        "del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c1suB9UG8oF9",
      "metadata": {
        "id": "c1suB9UG8oF9"
      },
      "outputs": [],
      "source": [
        "TEST_TRIPLETS = '/content/drive/MyDrive/task3_full/test_triplets.txt'\n",
        "\n",
        "# repeat for testing data\n",
        "X_test, y_test = get_data(TEST_TRIPLETS, train=False)\n",
        "test_loader = create_loader_from_np(X_test, train = False, batch_size=2048, shuffle=False)\n",
        "del X_test\n",
        "del y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_VnSbbNksYYi",
      "metadata": {
        "id": "_VnSbbNksYYi"
      },
      "outputs": [],
      "source": [
        "def validation_acc(validation_pred, validation_label):\n",
        "  acc = 0\n",
        "  assert(validation_pred.size() == validation_label.size())\n",
        "  for i in range(validation_pred.size()):\n",
        "    if validation_pred[i] == validation_label[i]:\n",
        "      acc+=1\n",
        "  return acc/validation_pred.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28634c90281cd699",
      "metadata": {
        "id": "28634c90281cd699"
      },
      "outputs": [],
      "source": [
        "def train_model_triplet(train_loader):\n",
        "    \"\"\"\n",
        "    The training procedure of the model; it accepts the training data, defines the model\n",
        "    and then trains it.\n",
        "\n",
        "    input: train_loader: torch.data.util.DataLoader, the object containing the training data\n",
        "\n",
        "    output: model: torch.nn.Module, the trained model\n",
        "    \"\"\"\n",
        "    model = TripletNet()\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    n_epochs = 10\n",
        "    # TODO: define a loss function, optimizer and proceed with training. Hint: use the part\n",
        "    # of the training data as a validation split. After each epoch, compute the loss on the\n",
        "    # validation split and print it out. This enables you to see how your model is performing\n",
        "    # on the validation data before submitting the results on the server. After choosing the\n",
        "    # best model, train it on the whole training data.\n",
        "\n",
        "    #use triplet loss?\n",
        "    criterion = nn.TripletMarginLoss(margin = 0.1)  # Define your loss function here\n",
        "    #criterion = nn.TripletMarginLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.1)  # Define your optimizer\n",
        "    acc=0\n",
        "    count=0\n",
        "    #best_model =  Net()\n",
        "\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        running_loss = 0.0\n",
        "        #define validation subset\n",
        "        #validation =\n",
        "\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            #print(\"i: \", i, \" Data: \", data, \"\\n\")\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            #print(\"Inputs:\", inputs.size(), \"Labels:\", labels.size(), \"\\n\")\n",
        "            labels = labels.type(torch.float)\n",
        "            anchor = inputs[:, :2048]\n",
        "            #print(anchor.shape)\n",
        "            positive = inputs[:,2048:4096]\n",
        "            negative = inputs[:,4096:]\n",
        "\n",
        "            anchor_embed, positive_embed, negative_embed = model(anchor, positive, negative)\n",
        "            loss = criterion(anchor_embed, positive_embed, negative_embed)\n",
        "\n",
        "            #print(\"anchor:\", anchor, \"positive:\", positive, \"negative:\", negative, \"\\n\")\n",
        "\n",
        "            # Calculate the Euclidean norm between anchor and positive embeddings\n",
        "            dist_positive = torch.norm(anchor_embed - positive_embed, dim=1)\n",
        "\n",
        "            # Calculate the Euclidean norm between anchor and negative embeddings\n",
        "            dist_negative = torch.norm(anchor_embed - negative_embed, dim=1)\n",
        "\n",
        "            # Print or use the distances as needed\n",
        "            #print(\"Euclidean distance between anchor and positive:\", dist_positive)\n",
        "            #print(\"Euclidean distance between anchor and negative:\", dist_negative)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            # Compute accuracy\n",
        "            acc = ((dist_positive >= dist_negative)==labels).sum().item()\n",
        "            count = len(labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 200 == 199:  # Print every 20 mini-batches\n",
        "                #for name, param in model.named_parameters():\n",
        "                #  print(name, param)\n",
        "                #print(predicted.sum())\n",
        "                accper = acc/count\n",
        "                print('[%d, %5d] loss: %.3f acc: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 200, accper))\n",
        "                print((dist_positive >= dist_negative))\n",
        "                running_loss = 0.0\n",
        "            # Get predicted classes as the entry with the highest probability\n",
        "\n",
        "          #score_validation = validation_acc(validation, model(validation))\n",
        "          #print(\"Epoch :\" epoch, \"Score: \", score_validation, \"\\n\")\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=train_model_triplet(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0gdqvWpNgsJ_",
        "outputId": "acbe42d1-aee0-4f9f-e94c-62ce3e472f19"
      },
      "id": "0gdqvWpNgsJ_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 0.101 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,   400] loss: 0.103 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,   600] loss: 0.099 acc: 1.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,   800] loss: 0.100 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  1000] loss: 0.097 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  1200] loss: 0.102 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  1400] loss: 0.097 acc: 1.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  1600] loss: 0.095 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  1800] loss: 0.102 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  2000] loss: 0.099 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  2200] loss: 0.095 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  2400] loss: 0.104 acc: 1.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  2600] loss: 0.099 acc: 1.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  2800] loss: 0.102 acc: 1.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  3000] loss: 0.102 acc: 1.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  3200] loss: 0.100 acc: 1.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  3400] loss: 0.101 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  3600] loss: 0.100 acc: 1.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  3800] loss: 0.099 acc: 1.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  4000] loss: 0.099 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  4200] loss: 0.100 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  4400] loss: 0.099 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  4600] loss: 0.102 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  4800] loss: 0.102 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  5000] loss: 0.101 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  5200] loss: 0.101 acc: 1.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  5400] loss: 0.101 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  5600] loss: 0.100 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  5800] loss: 0.099 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  6000] loss: 0.103 acc: 1.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  6200] loss: 0.101 acc: 1.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  6400] loss: 0.097 acc: 1.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  6600] loss: 0.097 acc: 1.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  6800] loss: 0.102 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  7000] loss: 0.096 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  7200] loss: 0.101 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  7400] loss: 0.102 acc: 1.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  7600] loss: 0.105 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  7800] loss: 0.099 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  8000] loss: 0.102 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  8200] loss: 0.102 acc: 0.000\n",
            "tensor([False], device='cuda:0')\n",
            "[1,  8400] loss: 0.099 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  8600] loss: 0.100 acc: 1.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  8800] loss: 0.097 acc: 1.000\n",
            "tensor([True], device='cuda:0')\n",
            "[1,  9000] loss: 0.102 acc: 0.000\n",
            "tensor([True], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-148 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 53, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 30, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
            "    c = SocketClient(address)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-181-0e68a6f77b30>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model_triplet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-180-0444a9a6583d>\u001b[0m in \u001b[0;36mtrain_model_triplet\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m#print(\"Euclidean distance between anchor and negative:\", dist_negative)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mdynamo_config_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0mper_device_and_dtype_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zero_grad_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, args)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \"\"\"\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-Bj0l2VZ3vff",
      "metadata": {
        "id": "-Bj0l2VZ3vff"
      },
      "outputs": [],
      "source": [
        "def train_model(train_loader):\n",
        "    \"\"\"\n",
        "    The training procedure of the model; it accepts the training data, defines the model\n",
        "    and then trains it.\n",
        "\n",
        "    input: train_loader: torch.data.util.DataLoader, the object containing the training data\n",
        "\n",
        "    output: model: torch.nn.Module, the trained model\n",
        "    \"\"\"\n",
        "    model = Net()\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    n_epochs = 10\n",
        "    # TODO: define a loss function, optimizer and proceed with training. Hint: use the part\n",
        "    # of the training data as a validation split. After each epoch, compute the loss on the\n",
        "    # validation split and print it out. This enables you to see how your model is performing\n",
        "    # on the validation data before submitting the results on the server. After choosing the\n",
        "    # best model, train it on the whole training data.\n",
        "\n",
        "    #use triplet loss?\n",
        "    criterion = nn.L1Loss()  # Define your loss function here\n",
        "    #criterion = nn.TripletMarginLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)  # Define your optimizer\n",
        "    acc=0\n",
        "    count=0\n",
        "    #best_model =  Net()\n",
        "\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        running_loss = 0.0\n",
        "        #define validation subset\n",
        "        #validation =\n",
        "\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            #print(\"i: \", i, \" Data: \", data, \"\\n\")\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            labels = labels.type(torch.float)\n",
        "            #print(\"Inputs:\", inputs.size(), \"Labels:\", labels.size(), \"\\n\")\n",
        "            outputs = model(inputs)\n",
        "            #print(\"Outputs:\", outputs, \"Labels:\", labels, \"\\n\")\n",
        "\n",
        "            loss = criterion(outputs.squeeze(), labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            outputs[outputs >= 0.5] = 1\n",
        "            outputs[outputs < 0.5] = 0\n",
        "            predicted = outputs\n",
        "\n",
        "            # Compute accuracy\n",
        "            acc += (predicted == labels).sum().item()\n",
        "            count +=len(labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 200 == 199:  # Print every 20 mini-batches\n",
        "                #for name, param in model.named_parameters():\n",
        "                #  print(name, param)\n",
        "                print(predicted.sum())\n",
        "                accper = acc/count\n",
        "                print('[%d, %5d] loss: %.3f acc: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 200, accper))\n",
        "                running_loss = 0.0\n",
        "            # Get predicted classes as the entry with the highest probability\n",
        "\n",
        "          #score_validation = validation_acc(validation, model(validation))\n",
        "          #print(\"Epoch :\" epoch, \"Score: \", score_validation, \"\\n\")\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2ea99b26c348253",
      "metadata": {
        "id": "b2ea99b26c348253"
      },
      "outputs": [],
      "source": [
        "def test_model(model, loader):\n",
        "    \"\"\"\n",
        "    The testing procedure of the model; it accepts the testing data and the trained model and\n",
        "    then tests the model on it.\n",
        "\n",
        "    input: model: torch.nn.Module, the trained model\n",
        "           loader: torch.data.util.DataLoader, the object containing the testing data\n",
        "\n",
        "    output: None, the function saves the predictions to a results.txt file\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    # Iterate over the test data\n",
        "    with torch.no_grad(): # We don't need to compute gradients for testing\n",
        "        for [x_batch] in loader:\n",
        "            x_batch= x_batch.to(device)\n",
        "            predicted = model(x_batch)\n",
        "            predicted = predicted.cpu().numpy()\n",
        "            # Rounding the predictions to 0 or 1\n",
        "            predicted[predicted >= 0.5] = 1\n",
        "            predicted[predicted < 0.5] = 0\n",
        "            #predicted = [i >= 0.5 for i in predicted]\n",
        "            predictions.append(predicted)\n",
        "        predictions = np.vstack(predictions)\n",
        "    np.savetxt(\"results.txt\", predictions, fmt='%i')\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40E4Pc1iOHvN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "40E4Pc1iOHvN",
        "outputId": "16ceee63-6c59-4bbe-99ed-8370a768f115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights of the linear layer:\n",
            "Parameter containing:\n",
            "tensor([[-0.0119, -0.0111, -0.0051,  ..., -0.0052, -0.0057,  0.0032],\n",
            "        [ 0.0020,  0.0070,  0.0078,  ...,  0.0089, -0.0108,  0.0073],\n",
            "        [ 0.0107,  0.0037, -0.0092,  ...,  0.0040, -0.0121, -0.0093],\n",
            "        ...,\n",
            "        [-0.0055,  0.0035, -0.0099,  ..., -0.0122,  0.0113, -0.0016],\n",
            "        [-0.0085,  0.0115,  0.0122,  ...,  0.0031, -0.0056, -0.0104],\n",
            "        [-0.0112,  0.0057, -0.0029,  ..., -0.0107, -0.0058,  0.0025]],\n",
            "       requires_grad=True)\n",
            "Initial bias of the linear layer:\n",
            "Parameter containing:\n",
            "tensor([ 0.0099,  0.0114, -0.0083,  ..., -0.0005,  0.0072,  0.0057],\n",
            "       requires_grad=True)\n",
            "Weights after Xavier initialization:\n",
            "Parameter containing:\n",
            "tensor([[ 0.0073, -0.0256,  0.0141,  ...,  0.0217, -0.0245, -0.0006],\n",
            "        [ 0.0079, -0.0226, -0.0252,  ...,  0.0188,  0.0005,  0.0167],\n",
            "        [-0.0262, -0.0227, -0.0199,  ...,  0.0171, -0.0052, -0.0253],\n",
            "        ...,\n",
            "        [ 0.0117, -0.0106,  0.0136,  ..., -0.0200, -0.0180, -0.0169],\n",
            "        [ 0.0216,  0.0266,  0.0149,  ..., -0.0184,  0.0042,  0.0209],\n",
            "        [-0.0195, -0.0252, -0.0007,  ...,  0.0197,  0.0181,  0.0198]],\n",
            "       requires_grad=True)\n",
            "Bias after initialization:\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,   200] loss: 3.145 acc: 16.005\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,   400] loss: 0.494 acc: 16.125\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,   600] loss: 0.498 acc: 16.110\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,   800] loss: 0.502 acc: 16.062\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  1000] loss: 0.496 acc: 16.090\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  1200] loss: 0.507 acc: 16.017\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  1400] loss: 0.501 acc: 15.961\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  1600] loss: 0.502 acc: 15.929\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  1800] loss: 0.500 acc: 15.948\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  2000] loss: 0.496 acc: 15.979\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  2200] loss: 0.494 acc: 16.001\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  2400] loss: 0.497 acc: 16.011\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  2600] loss: 0.500 acc: 16.011\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  2800] loss: 0.499 acc: 16.015\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  3000] loss: 0.507 acc: 15.992\n",
            "tensor(32., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  3200] loss: 0.502 acc: 15.977\n",
            "tensor(32., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  3400] loss: 0.500 acc: 15.982\n",
            "tensor(32., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[1,  3600] loss: 0.496 acc: 15.999\n",
            "tensor(32., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[2,   200] loss: 0.503 acc: 15.981\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[2,   400] loss: 0.496 acc: 16.000\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[2,   600] loss: 0.492 acc: 16.015\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[2,   800] loss: 0.501 acc: 16.013\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[2,  1000] loss: 0.497 acc: 16.019\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[2,  1200] loss: 0.495 acc: 16.026\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[2,  1400] loss: 0.507 acc: 16.016\n",
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[2,  1600] loss: 0.501 acc: 16.015\n",
            "tensor(32., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[2,  1800] loss: 0.504 acc: 15.999\n",
            "tensor(32., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "[2,  2000] loss: 0.499 acc: 16.007\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-197-4e1c507ec146>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-196-48754c19e126>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Compute accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model=train_model(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1U5OWSiJOfx2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U5OWSiJOfx2",
        "outputId": "7de67d3e-a299-4aa4-ae7c-285de27ce189"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       ...,\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_model(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}